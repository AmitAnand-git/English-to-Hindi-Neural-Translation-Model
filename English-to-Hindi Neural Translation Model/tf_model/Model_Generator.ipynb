{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KALYvZycPe8N",
        "outputId": "38037f78-470f-4f5f-df64-015e71d55178"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Mar 16 17:18:32 2024       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 551.76                 Driver Version: 551.76         CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 3050 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   47C    P0             14W /   60W |       0MiB /   4096MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#Checking if GPU is running or not\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_3XQ_jhwe0m5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers[sentencepiece] sacrebleu -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fr_hhoAFefza"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\amita\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import transformers\n",
        "import tensorflow as tf\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import TFAutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
        "from transformers import AdamWeightDecay\n",
        "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-dbDT2O9fJEp"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = \"Helsinki-NLP/opus-mt-en-hi\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q8AHfSWWMLm"
      },
      "source": [
        "## Helsinki-NLP/opus-mt-en-hi model\n",
        "\n",
        "source: https://huggingface.co/Helsinki-NLP/opus-mt-en-hi\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H3frhJQ_Lym"
      },
      "source": [
        "# The Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFmXYJQHBetF"
      },
      "source": [
        "Source: https://huggingface.co/datasets/cfilt/iitb-english-hindi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "daj9JBV6jDGK"
      },
      "outputs": [],
      "source": [
        "raw_datasets = load_dataset(\"cfilt/iitb-english-hindi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHdy5o8zsGhm",
        "outputId": "a6113742-60f2-4aad-f871-3057e6631b26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 1659083\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 520\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 2507\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfaNkUHNqU11",
        "outputId": "12276ba4-af83-43c9-94fb-eb4c19f4bbf6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'translation': {'en': 'Accerciser Accessibility Explorer',\n",
              "  'hi': 'एक्सेर्साइसर पहुंचनीयता अन्वेषक'}}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_datasets['train'][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x6TtxnEEDuw"
      },
      "source": [
        "#Preprocessing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "20qWg7z8qv7z"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYCILyEK0HXG",
        "outputId": "08d1bc6c-9619-4f17-9c6c-668a0ce09558"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [12110, 2, 90, 23, 19, 8800, 61, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer(\"Hello, this is a sentence!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDgcI2Nz0SZN",
        "outputId": "acf0766d-68d8-4240-e3c2-cfa33fa599c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [[12110, 2, 90, 23, 19, 8800, 61, 0], [239, 23, 414, 8800, 3, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer([\"Hello, this is a sentence!\", \"This is another sentence.\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh0epnye1JJk",
        "outputId": "0fb6a12c-9e29-494d-b3eb-16909889d8ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': [[26618, 16155, 346, 33383, 0]], 'attention_mask': [[1, 1, 1, 1, 1]]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\amita\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "with tokenizer.as_target_tokenizer():\n",
        "    print(tokenizer([\"एक्सेर्साइसर पहुंचनीयता अन्वेषक\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XHaFoHKG3snJ"
      },
      "outputs": [],
      "source": [
        "max_input_length = 128\n",
        "max_target_length = 128\n",
        "\n",
        "source_lang = \"en\"\n",
        "target_lang = \"hi\"\n",
        "\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [ex[source_lang] for ex in examples[\"translation\"]]\n",
        "    targets = [ex[target_lang] for ex in examples[\"translation\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
        "\n",
        "    # Setup the tokenizer for targets\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX9vN5Yo4kuG",
        "outputId": "4229da35-1d91-40b2-8cd1-793e454574fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [[3872, 85, 2501, 132, 15441, 36398, 0], [32643, 28541, 36253, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1]], 'labels': [[63, 2025, 18, 16155, 346, 20311, 24, 2279, 679, 0], [26618, 16155, 346, 33383, 0]]}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocess_function(raw_datasets[\"train\"][:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PTzg3eWK4_FG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 1659083/1659083 [03:12<00:00, 8628.46 examples/s] \n",
            "Map: 100%|██████████| 520/520 [00:00<00:00, 6027.98 examples/s]\n",
            "Map: 100%|██████████| 2507/2507 [00:00<00:00, 5901.94 examples/s]\n"
          ]
        }
      ],
      "source": [
        "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEbE41CbU1bL",
        "outputId": "502cb1cc-5596-476b-fe6a-9f8474e98aa9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-hi.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "GOJU15XzX5iy"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "learning_rate = 2e-5\n",
        "weight_decay = 0.01\n",
        "num_train_epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "NCoU8kNtX6Tk"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4IbSTkjuYZ8Z"
      },
      "outputs": [],
      "source": [
        "generation_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\", pad_to_multiple_of=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "AgvwEEvDZP7F"
      },
      "outputs": [],
      "source": [
        "train_dataset = model.prepare_tf_dataset(\n",
        "    tokenized_datasets[\"train\"],\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "VMrJxDAwqlcW"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_dataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain_dataset\u001b[49m)\n\u001b[0;32m      2\u001b[0m subset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(num_samples \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.1\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ],
      "source": [
        "num_samples = len(train_dataset)\n",
        "subset_size = int(num_samples * 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxqMlcPRqqfP"
      },
      "outputs": [],
      "source": [
        "train_subset = train_dataset.take(subset_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYpSLXoDpJEm",
        "outputId": "c88ba477-6448-4a10-e516-f7f5c9dde18a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train': (1659083, 1), 'validation': (520, 1), 'test': (2507, 1)}\n"
          ]
        }
      ],
      "source": [
        "print(raw_datasets.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "E_1LNLwvZQvD"
      },
      "outputs": [],
      "source": [
        "validation_dataset = model.prepare_tf_dataset(\n",
        "    tokenized_datasets[\"validation\"],\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=data_collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GYF9ApeHZTR5"
      },
      "outputs": [],
      "source": [
        "generation_dataset = model.prepare_tf_dataset(\n",
        "    tokenized_datasets[\"validation\"],\n",
        "    batch_size=8,\n",
        "    shuffle=False,\n",
        "    collate_fn=generation_data_collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Wx6p1NQ_ZVXb"
      },
      "outputs": [],
      "source": [
        "optimizer = AdamWeightDecay(learning_rate=learning_rate, weight_decay_rate=weight_decay)\n",
        "model.compile(optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G5WXVp0Z15g",
        "outputId": "52920543-07ea-4cf1-8df1-e088fee54fd9"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_subset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mtrain_subset\u001b[49m, validation_data\u001b[38;5;241m=\u001b[39mvalidation_dataset, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'train_subset' is not defined"
          ]
        }
      ],
      "source": [
        "model.fit(train_subset, validation_data=validation_dataset, epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "4EWkhFnyZ3Z8"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"tf_model/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcGNz4yrMY4F"
      },
      "outputs": [],
      "source": [
        "# Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTkqZ2fuLbd1",
        "outputId": "e0c7316e-af98-44c7-a6d0-c8e7e5b35132"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 2) (1094967974.py, line 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[28], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    model = TFAutoModelForSeq2SeqLM.from_pretrained(r\"D:\\PYTHON\\PY eng 2 hin\\tf_model\\\")\u001b[0m\n\u001b[1;37m                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 2)\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(r\"D:\\PYTHON\\PY eng 2 hin\\tf_model\\\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4-NztUuM6pk",
        "outputId": "38b66aed-08be-4ce0-9a4c-09ec3cc7da95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[61949  4952     2    60   356  1266     6   116  8687   130  5029  8653\n",
            "      9 10430     5    40     0]], shape=(1, 17), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "input_text  = \"Hey, this is Ajay Kumar and team, with our project  \"\n",
        "\n",
        "tokenized = tokenizer([input_text], return_tensors='np')\n",
        "out = model.generate(**tokenized, max_length=128)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OIrGT1uOjKe",
        "outputId": "cbf9035f-9624-4dbc-d8fc-5bafd9d8b71d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "अरे, यह हमारी परियोजना के साथ अली कुमार और टीम है।\n"
          ]
        }
      ],
      "source": [
        "with tokenizer.as_target_tokenizer():\n",
        "    print(tokenizer.decode(out[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "_WjVcYschmbn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
